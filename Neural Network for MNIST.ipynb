{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "obKhDyhCPFSh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision ## Contains some utilities for working with the image data\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def relu(x):\n",
        "\treturn max(0.0, x)\n",
        "\n",
        "def relu_(x):\n",
        "  if x > 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def sig(x):\n",
        " return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sig_(x):\n",
        "  return sig(x)*(1-sig(x))"
      ],
      "metadata": {
        "id": "iYxU4hsYPIxw"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f(x)\n",
        "def f_x(weight_v, weight_w, x, k):\n",
        "  phi = [[0] for i in range(k)]\n",
        "  x_T = np.array(x).T\n",
        "  w = []\n",
        "  v = []\n",
        "  # calculate phi\n",
        "  for j in range(k):\n",
        "    temp = weight_w[j]\n",
        "    w.append(temp)\n",
        "    w_mul_x_T = np.array(w).dot(np.array(x_T))\n",
        "    # relu\n",
        "    phi[j][0] = sig(w_mul_x_T[0])\n",
        "    w = []\n",
        "  v.append(weight_v)\n",
        "  v_mul_phi = np.array(v).dot(np.array(phi))\n",
        "  v = []\n",
        "  if sig(v_mul_phi[0]) > 0.5:\n",
        "    y = 1\n",
        "  else:\n",
        "    y = 0\n",
        "  return y\n",
        "\n",
        "# f(x)'\n",
        "def f_x_(weight_v, weight_w, x, k):\n",
        "  phi = [[0] for i in range(k)]\n",
        "  x_T = np.array(x).T\n",
        "  w = []\n",
        "  # calculate phi\n",
        "  for j in range(k):\n",
        "    temp = weight_w[j]\n",
        "    w.append(temp)\n",
        "    w_mul_x_T = np.array(w).dot(np.array(x_T))\n",
        "    phi[j][0] = sig_(w_mul_x_T[0])\n",
        "    w = []\n",
        "  v = weight_v\n",
        "\n",
        "  output = [[0] for b in range(k)]\n",
        "  for a in range(k):\n",
        "    output[a][0] = v[a][0] * phi[a][0]\n",
        "\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "JHHppJPoPPqF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "def ac(weight_v, weight_w, flat_test_data, Y_test, k):\n",
        "  accurate = 0\n",
        "  for i in range(n_test):\n",
        "    predict = f_x(weight_v, weight_w, flat_test_data[i], k)\n",
        "    if predict == Y_test[i][0]:\n",
        "      accurate += 1\n",
        "  accuracy = accurate/10000\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "j7LZpUSGPbXS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ac_train(weight_v, weight_w, dataset, Y, k):\n",
        "  accurate = 0\n",
        "  for i in range(n_train):\n",
        "    predict = f_x(weight_v, weight_w, flat_train_data[i], k)\n",
        "    if predict == Y[i][0]:\n",
        "      accurate += 1\n",
        "  accuracy = accurate/n_train\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "OH42hujvKzkL"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate gradient of weight w\n",
        "def g_W(weight_w, l, weight_v, x, y, k):\n",
        "  v = []\n",
        "  g = [[0 for i in range(785)] for j in range(k)]\n",
        "  f = f_x(weight_v, weight_w, x, k)\n",
        "  temp1 = l*(f - y)\n",
        "  v.append(weight_v)\n",
        "  # make v_t (5x1) size matrix\n",
        "  v_T = np.array(v).T\n",
        "  # f_x_ is (5x1) matrix\n",
        "  temp2 = f_x_(v_T, weight_w, x, k)\n",
        "  temp3 = temp1*np.array(temp2)\n",
        "  x_temp = []\n",
        "  x_temp.append(x)\n",
        "  g = np.array(temp3).dot(x_temp)\n",
        "\n",
        "  return g\n",
        "\n",
        "# calculate gradient of weight v\n",
        "def g_v(weight_w, l, weight_v, x, y, k):\n",
        "  temp1 = l*f_x(weight_v, weight_w, x, k)\n",
        "  phi = [[0] for i in range(k)]\n",
        "  x_T = np.array(x).T\n",
        "  w = []\n",
        "  # calculate phi\n",
        "  for j in range(k):\n",
        "    temp = weight_w[j]\n",
        "    w.append(temp)\n",
        "    w_mul_x_T = np.array(w).dot(np.array(x_T))\n",
        "    # relu\n",
        "    phi[j][0] = sig(w_mul_x_T[0])\n",
        "    w = []\n",
        "  g = temp1*np.array(phi)\n",
        "\n",
        "  return g"
      ],
      "metadata": {
        "id": "7V1o3w4TPfCu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MNIST dataset(images and labels)\n",
        "#use ToTensor() transform to convert images into Pytorch tensors.\n",
        "train_data = MNIST(root = 'data/', train = True, download = True, transform = transforms.ToTensor())\n",
        "test_data = MNIST(root = 'data/', train = False, download = True, transform = transforms.ToTensor())\n",
        "\n",
        "\n",
        "n_train = 50000\n",
        "n_test = 10000\n",
        "\n",
        "# formatting training data\n",
        "flat_train_data = [[0] for i in range(n_train)]\n",
        "train_data_label = [0 for i in range(n_train)]\n",
        "for i in range(n_train):\n",
        "  #temp = random.randrange(60000)\n",
        "  image_tensor, label = train_data[i]\n",
        "  flat_train_data[i] = image_tensor[:,0:28,0:28].flatten().tolist()\n",
        "  #flat_train_data[i].append(label)\n",
        "  train_data_label[i] = label\n",
        "\n",
        "# formatting testing data\n",
        "flat_test_data = [[0] for i in range(n_test)]\n",
        "test_data_label = [0 for i in range(n_test)]\n",
        "for i in range(n_test):\n",
        "    image_tensor, label = test_data[i]\n",
        "    flat_test_data[i] = image_tensor[:,0:28,0:28].flatten().tolist()\n",
        "    test_data_label[i] = label"
      ],
      "metadata": {
        "id": "lk70roegPnLy"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# z-normalization\n",
        "\n",
        "# mean across the training data\n",
        "mean = np.mean(np.array(flat_train_data))\n",
        "# standard deviation across the training data\n",
        "std = np.std(np.array(flat_train_data))\n",
        "\n",
        "# standardize training data by x = (x-mean)/std\n",
        "for i in range(n_train):\n",
        "  temp = np.array(flat_train_data[i])\n",
        "  flat_train_data[i] = np.divide(np.subtract(temp, mean), std)\n",
        "# standardize testing data by x = (x-mean)/std\n",
        "for i in range(n_test):\n",
        "  temp = np.array(flat_test_data[i])\n",
        "  flat_test_data[i] = np.divide(np.subtract(temp, mean), std)\n",
        "\n",
        "# Add bias variable by concatenating 1\n",
        "# make the dimension d=785 for each input x\n",
        "for i in range(n_train):\n",
        "  flat_train_data[i] = np.append(flat_train_data[i], 1)\n",
        "for i in range(n_test):\n",
        "  flat_test_data[i] = np.append(flat_test_data[i], 1)"
      ],
      "metadata": {
        "id": "p8_3FZ0aPnzz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize Y in binary\n",
        "Y = [[0] for j in range(n_train)]\n",
        "for i in range(n_train):\n",
        "\t#Y[i][train_data_label[i]] = 1\n",
        "  if train_data_label[i] >= 5:\n",
        "    Y[i][0] = 1\n",
        "  else:\n",
        "    Y[i][0] = 0\n",
        "\n",
        "# convert label of test data to binary\n",
        "Y_test = [[0] for j in range(n_test)]\n",
        "for i in range(n_test):\n",
        "  if test_data_label[i] >= 5:\n",
        "    Y_test[i][0] = 1\n",
        "  else:\n",
        "    Y_test[i][0] = 0"
      ],
      "metadata": {
        "id": "4QX544wrPp-4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle data for sgd\n",
        "def shuffle_data(flat_train_data, Y):\n",
        "  temp = [[0 for i in range(786)] for j in range(n_train)]\n",
        "  for i in range(n_train):\n",
        "    temp[i] = np.append(flat_train_data[i], Y[i])\n",
        "\n",
        "  np.random.shuffle(temp)\n",
        "  train_data = [[0 for i in range(785)] for j in range(n_train)]\n",
        "  train_data_label = [0 for i in range(n_train)]\n",
        "  for i in range(n_train):\n",
        "    train_data[i] = temp[i][0:785]\n",
        "    train_data_label[i] = temp[i][-1]\n",
        "\n",
        "  return train_data, train_data_label"
      ],
      "metadata": {
        "id": "gKkIR_gUQCMT"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize v, w with gaussian distribution\n",
        "d = 785\n",
        "k = 5\n",
        "# W: R_k*d\n",
        "W0 = [[0 for i in range(d)] for j in range(k)]\n",
        "for i in range(k):\n",
        "  for j in range(d):\n",
        "    temp = random.gauss(0, 1/d)\n",
        "    W0[i][j] = temp\n",
        "# v: R_k\n",
        "v0 = [0 for i in range(k)]\n",
        "for i in range(k):\n",
        "  temp = random.gauss(0, 1/k)\n",
        "  v0[i] = temp"
      ],
      "metadata": {
        "id": "aTStHDhXQEwn"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sgd\n",
        "\n",
        "#learning rate\n",
        "l = 0.00001\n",
        "#l = 0.5\n",
        "k = 5\n",
        "b = 10\n",
        "v = v0\n",
        "w = W0\n",
        "count = 0\n",
        "p = []\n",
        "p_train = []\n",
        "ip = []\n",
        "\n",
        "for epoch in range(10):\n",
        "  print(\"epoch is {epoch}\".format(epoch = epoch))\n",
        "  train_data, train_data_label = shuffle_data(flat_train_data, Y)\n",
        "  index = 0\n",
        "  for iter in range(5000):\n",
        "    count += 1\n",
        "    if count % 1000 == 0:\n",
        "      accuracy = ac(v, w, flat_test_data, Y_test, k)\n",
        "      accuracy_train = ac_train(v, w, train_data, Y, k)\n",
        "      print(\"iteration is {iter}\".format(iter = iter))\n",
        "      print(\"accuracy is {accuracy}\".format(accuracy = accuracy))\n",
        "      print(\"training accuracy is {accuracy}\".format(accuracy = accuracy_train))\n",
        "      p.append(accuracy)\n",
        "      p_train.append(accuracy_train)\n",
        "      ip.append(count)\n",
        "    total_gw = 0\n",
        "    total_gv = 0\n",
        "    for batch in range(b):\n",
        "      # calculate gradient g\n",
        "      index += 1\n",
        "      if index == 5000:\n",
        "        index = 0\n",
        "      x = train_data[index]\n",
        "      y = train_data_label[index]\n",
        "      total_gw += g_W(w, l, v, x, y, k)\n",
        "      total_gv += g_v(w, l, v, x, y, k)\n",
        "    Gw = total_gw/b\n",
        "    Gv = total_gv/b\n",
        "    w -= Gw\n",
        "    a = np.array(Gv).T[0]\n",
        "    v -= a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8al_u82_QGtH",
        "outputId": "3c102ea5-954a-4bd4-96db-d13349ee08d8"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch is 0\n",
            "iteration is 999\n",
            "accuracy is 0.5139\n",
            "training accuracy is 0.51076\n",
            "iteration is 1999\n",
            "accuracy is 0.5415\n",
            "training accuracy is 0.53684\n",
            "iteration is 2999\n",
            "accuracy is 0.5976\n",
            "training accuracy is 0.5782\n",
            "iteration is 3999\n",
            "accuracy is 0.6119\n",
            "training accuracy is 0.5957\n",
            "iteration is 4999\n",
            "accuracy is 0.6236\n",
            "training accuracy is 0.6062\n",
            "epoch is 1\n",
            "iteration is 999\n",
            "accuracy is 0.6328\n",
            "training accuracy is 0.6139\n",
            "iteration is 1999\n",
            "accuracy is 0.6395\n",
            "training accuracy is 0.62052\n",
            "iteration is 2999\n",
            "accuracy is 0.6463\n",
            "training accuracy is 0.62648\n",
            "iteration is 3999\n",
            "accuracy is 0.6507\n",
            "training accuracy is 0.63096\n",
            "iteration is 4999\n",
            "accuracy is 0.655\n",
            "training accuracy is 0.6351\n",
            "epoch is 2\n",
            "iteration is 999\n",
            "accuracy is 0.6585\n",
            "training accuracy is 0.64056\n",
            "iteration is 1999\n",
            "accuracy is 0.6623\n",
            "training accuracy is 0.64356\n",
            "iteration is 2999\n",
            "accuracy is 0.6649\n",
            "training accuracy is 0.6464\n",
            "iteration is 3999\n",
            "accuracy is 0.6674\n",
            "training accuracy is 0.64852\n",
            "iteration is 4999\n",
            "accuracy is 0.6689\n",
            "training accuracy is 0.6511\n",
            "epoch is 3\n",
            "iteration is 999\n",
            "accuracy is 0.6711\n",
            "training accuracy is 0.6514\n",
            "iteration is 1999\n",
            "accuracy is 0.6714\n",
            "training accuracy is 0.65186\n",
            "iteration is 2999\n",
            "accuracy is 0.6723\n",
            "training accuracy is 0.65304\n",
            "iteration is 3999\n",
            "accuracy is 0.6725\n",
            "training accuracy is 0.654\n",
            "iteration is 4999\n",
            "accuracy is 0.6745\n",
            "training accuracy is 0.65496\n",
            "epoch is 4\n",
            "iteration is 999\n",
            "accuracy is 0.6764\n",
            "training accuracy is 0.6567\n",
            "iteration is 1999\n",
            "accuracy is 0.6779\n",
            "training accuracy is 0.65772\n",
            "iteration is 2999\n",
            "accuracy is 0.6785\n",
            "training accuracy is 0.65868\n",
            "iteration is 3999\n",
            "accuracy is 0.679\n",
            "training accuracy is 0.65958\n",
            "iteration is 4999\n",
            "accuracy is 0.6799\n",
            "training accuracy is 0.66034\n",
            "epoch is 5\n",
            "iteration is 999\n",
            "accuracy is 0.6804\n",
            "training accuracy is 0.66064\n",
            "iteration is 1999\n",
            "accuracy is 0.681\n",
            "training accuracy is 0.66126\n",
            "iteration is 2999\n",
            "accuracy is 0.6835\n",
            "training accuracy is 0.66182\n",
            "iteration is 3999\n",
            "accuracy is 0.6844\n",
            "training accuracy is 0.66248\n",
            "iteration is 4999\n",
            "accuracy is 0.6846\n",
            "training accuracy is 0.66298\n",
            "epoch is 6\n",
            "iteration is 999\n",
            "accuracy is 0.6846\n",
            "training accuracy is 0.66378\n",
            "iteration is 1999\n",
            "accuracy is 0.6857\n",
            "training accuracy is 0.66404\n",
            "iteration is 2999\n",
            "accuracy is 0.6863\n",
            "training accuracy is 0.66418\n",
            "iteration is 3999\n",
            "accuracy is 0.6868\n",
            "training accuracy is 0.6644\n",
            "iteration is 4999\n",
            "accuracy is 0.6872\n",
            "training accuracy is 0.66464\n",
            "epoch is 7\n",
            "iteration is 999\n",
            "accuracy is 0.6881\n",
            "training accuracy is 0.6653\n",
            "iteration is 1999\n",
            "accuracy is 0.6889\n",
            "training accuracy is 0.66572\n",
            "iteration is 2999\n",
            "accuracy is 0.6888\n",
            "training accuracy is 0.6658\n",
            "iteration is 3999\n",
            "accuracy is 0.689\n",
            "training accuracy is 0.66588\n",
            "iteration is 4999\n",
            "accuracy is 0.6885\n",
            "training accuracy is 0.66584\n",
            "epoch is 8\n",
            "iteration is 999\n",
            "accuracy is 0.6886\n",
            "training accuracy is 0.665\n",
            "iteration is 1999\n",
            "accuracy is 0.6874\n",
            "training accuracy is 0.66448\n",
            "iteration is 2999\n",
            "accuracy is 0.6868\n",
            "training accuracy is 0.66384\n",
            "iteration is 3999\n",
            "accuracy is 0.6863\n",
            "training accuracy is 0.66344\n",
            "iteration is 4999\n",
            "accuracy is 0.6864\n",
            "training accuracy is 0.66326\n",
            "epoch is 9\n",
            "iteration is 999\n",
            "accuracy is 0.6866\n",
            "training accuracy is 0.66372\n",
            "iteration is 1999\n",
            "accuracy is 0.6869\n",
            "training accuracy is 0.66386\n",
            "iteration is 2999\n",
            "accuracy is 0.6869\n",
            "training accuracy is 0.66374\n",
            "iteration is 3999\n",
            "accuracy is 0.6867\n",
            "training accuracy is 0.6634\n",
            "iteration is 4999\n",
            "accuracy is 0.6862\n",
            "training accuracy is 0.66324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('iteration (s)')\n",
        "ax1.set_ylabel('accuracy_test', color=color)\n",
        "#plt.ylabel('accuracy')\n",
        "#plt.xlabel('iteration')\n",
        "ax1.plot(ip, p, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('acuracy_train', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(ip, p_train, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "ZK57CNS1V-rh",
        "outputId": "ffc7f60f-c52b-4942-f58e-86873130a450"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cccb403d7d99>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#plt.ylabel('accuracy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#plt.xlabel('iteration')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ip' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}